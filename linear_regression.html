<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>California Housing Price Prediction using Linear Regression</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <!-- HEADER / NAVBAR (Matches index.html style) -->
  <header class="site-header">
    <div class="logo-and-name">
      <!-- Optional thumbnail:
      <img 
        src="profile_pic.jpeg" 
        alt="Udit Ekansh Thumbnail" 
        class="site-logo"
      /> -->
      <span class="site-title">Udit Ekansh</span>
    </div>
    <nav class="main-nav">
      <ul>
        <li><a href="index.html#about">About</a></li>
        <li><a href="index.html#research">Research</a></li>
        <li><a href="index.html#projects">Projects</a></li>
        <li><a href="index.html#certificates">Certificates</a></li>
        <li><a href="index.html#courses">Courses</a></li>
        <li><a href="index.html#publications">Publications</a></li>
        <li><a href="index.html#misc">Misc</a></li>
        <li><a href="index.html#connect">Connect</a></li>
      </ul>
    </nav>
  </header>

  <!-- HERO / TITLE SECTION -->
  <section class="hero-section">
    <h1>California Housing Price Prediction using Linear Regression</h1>
  </section>

  <!-- EXACT PROJECT CONTENT (unchanged) -->
  <section style="margin-top:1rem; text-align:left; max-width:600px; margin:auto;">
    <ul>
      <li>
<!--         <strong>California Housing Price Prediction using Linear Regression:</strong> -->
        <p>
          In this project, I tackled the task of <strong>predicting housing prices</strong> using the 
          <a href="https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html" target="_blank" style="text-decoration: underline;"> California Housing Dataset </a>.
          Instead of relying on pre-built linear regression implementations
          from libraries like Scikit-Learn or PyTorch, I chose to build the model from <strong>scratch</strong>, applying the closed-form solution of
          linear regression (Normal Equation). This hands-on approach deepened
          my understanding of the mathematical foundations behind linear regression while allowing me to control every step of the training process.
        </p>
        <p>
            The workflow began with data preprocessing, where I shuffled the dataset, performed an 80-20 train-test split, and applied feature scaling using
            <strong>min-max normalization.</strong> 
            I added a bias term to the feature matrix before calculating the weight vector analytically, ensuring that the model was built entirely from first principles. 
            By avoiding black-box implementations, I gained valuable insight into how feature transformations, scaling, and bias terms influence model performance.          
            To assess the model's effectiveness, I evaluated it using standard metrics: <strong>Mean Absolute Error (MAE)</strong> ,<strong>Mean Squared Error (MSE)</strong> ,
            and <strong>Root Mean Squared Error (RMSE).</strong> 
            The results were promising, with an RMSE of approximately  <strong>0.74 on the training set and 0.75 on the test set</strong>, indicating that the model generalized well 
            to unseen data.
        </p>

        <!-- Adding Images with Captions -->
        <div style="text-align: center; margin: 20px 0;">
            <figure>
                <img src="pred_vs_actual.png" alt="Predicted vs Actual for Training Set" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 1:</strong> Predicted vs Actual values.</figcaption>
            </figure>
        
            <figure>
                <img src="pred_vs_error.png" alt="Predictions vs Errors for Test and Training Sets" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 2:</strong> Predictions vs Errors.</figcaption>
            </figure>
        </div>
            
            I also visualized the model's predictions against actual values and plotted the distribution of residuals. Importantly, I generated <strong>Q-Q plots</strong> to verify
            one of the core assumptions of linear regression: that errors should follow a roughly normal distribution. 
            While the residuals were reasonably well-behaved, some deviations from normality suggested potential areasfor improvement, 
            such as exploring polynomial features or regularization techniques to better capture non-linear relationships.
        </p>
          <!-- Adding Images with Captions -->
        <div style="text-align: center; margin: 20px 0;">
            <figure>
                <img src="error_dist.png" alt="Error Distribution shows approximate Guassian Trend" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 1:</strong> Error Distribution confirms approximate normality..</figcaption>
            </figure>
        
            <figure>
                <img src="qqplot.png" alt="Q-Q Plot of Errors" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 2:</strong> Q-Q Plot of Errors.</figcaption>
            </figure>
        </div>
        <p>
            Through this project, I not only built a functional predictive model but also gained a more intuitive grasp of linear regression's 
            strengths and limitations. The process highlighted how theoretical understanding translates into practical application,
            while the residual analysis emphasized the importance of critically evaluating model assumptions rather than solely relying on performance metrics.
       </p>  
          
        <p>
          The code for this project can be found <a href="https://github.com/Udit176/CaliforniaHousingPredictions.git" target="_blank" style="text-decoration: underline;">here</a>.
        </p>
  </section>

  <!-- FOOTER (Optional) -->
  <footer class="site-footer" style="text-align:center; margin-top:2rem;">
    <p>Â© 2024 Udit Ekansh. All rights reserved.</p>
  </footer>

</body>
</html>

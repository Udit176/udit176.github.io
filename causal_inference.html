<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1.0"/>
  <title>Causal Inference as an Inductive Bias in Reinforcement Learning</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>

  <!-- HEADER / NAVBAR (Same as other pages) -->
  <header class="site-header">
    <div class="logo-and-name">
      <span class="site-title">Udit Ekansh</span>
    </div>
    <nav class="main-nav">
      <ul>
        <li><a href="index.html#about">About</a></li>
        <li><a href="index.html#research">Research</a></li>
        <li><a href="index.html#projects">Projects</a></li>
        <li><a href="index.html#certificates">Certificates</a></li>
        <li><a href="index.html#courses">Courses</a></li>
        <li><a href="index.html#publications">Publications</a></li>
        <li><a href="index.html#misc">Misc</a></li>
        <li><a href="index.html#connect">Connect</a></li>
      </ul>
    </nav>
  </header>

  <!-- HERO / TITLE SECTION -->
  <section class="hero-section">
    <h1>Causal Inference as an Inductive Bias in Reinforcement Learning</h1>
  </section>

  <!-- PROJECT DESCRIPTION -->
  <section style="margin-top:1rem; text-align:left; max-width:600px; margin:auto;">
    <ul>
      <li>
        <p>
          In this project, we explored whether embedding <strong>causal inductive biases</strong> into reinforcement learning (RL) could improve generalization under distributional shifts. Using the <a href="https://causalworld.org/" target="_blank" style="text-decoration: underline;">CausalWorld environment</a>, we compared standard model-free baselines like Soft Actor-Critic (SAC) with several <strong>causal RL variants</strong> including the CausalCF algorithm, which incorporates <strong>intervention</strong> and <strong>counterfactual reasoning</strong> to enhance learning.
        </p>

        <p>
          We trained all agents on a robotic picking task and evaluated them under 12 perturbation protocols (P0–P11) designed to introduce domain shifts (e.g., object mass, size, pose, and floor friction). We then assessed transferability by reusing the learned causal modules from the picking task to fine-tune the agent on a distinct pushing task. Our primary evaluation metric was <strong>fractional success</strong>, which measures how closely the agent’s configuration matches the target.
        </p>

        <p>
          Results demonstrated that causal agents—especially those trained with both interventions and counterfactuals—<strong>generalized better</strong> than non-causal SAC baselines in moderate domain shifts. The <strong>Transfer-CausalRep</strong> model also achieved competitive performance on the pushing task without retraining its causal modules, supporting the hypothesis that learned causal structure improves <strong>transfer and robustness</strong>. However, all models struggled under severe shifts (P10–P11), pointing to open challenges in causal RL.
        </p>

        <!-- Optional Figures Section -->
        <!--
        <div style="text-align: center; margin: 20px 0;">
            <figure>
                <img src="causalcf_barplot.png" alt="CausalCF Performance Summary" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 1:</strong> Fractional success across protocols for causal vs. non-causal agents.</figcaption>
            </figure>
        
            <figure>
                <img src="causalcf_radar.png" alt="Radar Plot Comparison" style="width: 500px; height: auto;">
                <figcaption><strong>Figure 2:</strong> Radar plots highlighting generalization patterns.</figcaption>
            </figure>
        </div>
        -->

        <p>
          Through this study, I gained hands-on experience in <strong>causal reasoning, inductive bias design, policy transfer</strong>, and evaluating generalization in robotic agents. This work illustrates the practical value of integrating <strong>structural knowledge</strong> into reinforcement learning, and motivates further exploration of scalable causal RL frameworks in real-world systems.
        </p>

        <p>
          The complete report can be accessed <a href="CS578_FinalReport.pdf" target="_blank" style="text-decoration: underline;">here</a>. Code is based on the official <a href="https://github.com/Tom1042roboai/CausalCF" target="_blank" style="text-decoration: underline;">CausalCF repository</a> with extensions for evaluation and transfer learning.
        </p>
      </li>
    </ul>
  </section>

  <!-- FOOTER -->
  <footer class="site-footer" style="text-align:center; margin-top:2rem;">
    <p>© 2024 Udit Ekansh. All rights reserved.</p>
  </footer>

</body>
</html>

